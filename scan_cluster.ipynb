{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Scan Cluster\n",
        "Scan Clusters is a program to look for homologous clusters in bacterial (but could also work on eukaryotes and viruses) genomes. If only a query cluster is provided the program will build HMMs for each gen in the cluster and then it will use hmmsearch to find the homologous genes in all the subject genomes. Homologous protein searches can be done in remote or local mode. For the remote mode, Scan_cluster will try to run blastp _-remote_ searches to retrieve homologous proteins. Then from the filtered blast results it will make the HMMs. In local mode, it will use a provided blast database or make a local Blast database from all the genomes to be analyzed, and run local blastp searches. From these searches the HMMs will be constructed. Alternatively, scan_cluster can search for clusters containing a predefined set of HMM. Finally, it can search for homologous of the proteins in the query cluster using blastp instead of hmmsearch.\n",
        "\n",
        "A cluster is then defined if there are multiple query protein hits in the same region of the target genome.\n",
        "The following criteria is used for cluster definition:\n",
        "*n_prots_between argument specifies the maximum number of proteins allowed between two consecutive genes in the query cluster.\n",
        "*max_alien_prots argument specifies the maximum number of proteins in the target cluster that are not present in the query cluster.\n",
        "*min_target_prots argument specifies the minimum of query proteins required to be found in target cluster. Default=3.)\n",
        "*min_cluster_coverage argument specifies the minimum of cluster coverage (proportion). Default=.5. The program will use as minimum half of the query proteins.\n",
        "\n",
        "The best clusters are then compared by pairwise blastp and a multiple cluster alignment (MCA) is generated by a progressive algorithm using dynamic programming. The scoring scheme for the MCA uses the orientation and pairwise identity values between all proteins in the clusters. Gaps are introduced when alien genes are present in the target clusters or when query genes are missing.\n",
        "The guide tree used in the MCA is reported jointly with an annotation file for ITOL.\n",
        "The clusters are also exported in genbank format to perform the cluster analysis with _Clinker_ software.\n",
        "\n",
        "![algorithm](https://github.com/maurijlozano/scan_cluster/blob/main/algorithm.png?raw=true)"
      ],
      "metadata": {
        "id": "mIjxk60lJbBk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Command line arguments\n",
        "```\n",
        "usage: scan_cluster.py [-h] [-Q QFILE] [-R REPID] [-s CSTART] [-e CEND]\n",
        "                       [-q QCLUSTER] [--Reference REFGENOME] [-f HMM_FOLDER]\n",
        "                       [-S SFILE] [-F SFOLDER] [-E GBEXT] [-o RES_FOLDER]\n",
        "                       [--overwrite] [--only_blastp] [-n PROTS_BETWEEN]\n",
        "                       [-M MAX_ALIEN_PROTS] [-m MIN_TARGET_PROTS]\n",
        "                       [--min_cluster_coverage MIN_CLUSTER_COVERAGE] [-g GAP]\n",
        "                       [--mismatch_score MISMATCH]\n",
        "                       [--local_blast_db LOCAL_BLAST_DB] [--Generate_local_db]\n",
        "                       [--Blast_DB BLASTP_DATABASE] [--Blast_evalue EVALUE]\n",
        "                       [--Blast_max_targets MAX_TARGET] [--Blast_qcov QCOV]\n",
        "                       [--Blast_scov SCOV] [--hmm_evalue HMM_EVALUE]\n",
        "                       [--hmm_cover HMM_COVER]\n",
        "\n",
        "This program was designed to identify orthologous genes clusters.\n",
        "\n",
        "options:\n",
        "  -h, --help            show this help message and exit\n",
        "\n",
        "Query cluster:\n",
        "  -Q QFILE, --QueryFile QFILE\n",
        "                        Query genome in Genbank format.\n",
        "  -R REPID, --Replicon_ID REPID\n",
        "                        Required for draft and multireplicon genomes.\n",
        "  -s CSTART, --cluster_start CSTART\n",
        "                        Genome cluster start location.\n",
        "  -e CEND, --cluster_end CEND\n",
        "                        Genome cluster end location.\n",
        "\n",
        "To search or a cluster provided in Genbank format:\n",
        "  -q QCLUSTER, --QueryCluster QCLUSTER\n",
        "                        Query cluster in Genbank format.\n",
        "  --Reference REFGENOME\n",
        "                        Specifies the genome Gb file to be used as reference.\n",
        "\n",
        "To search or a cluster with a defined set of protein HMMs:\n",
        "  -f HMM_FOLDER, --hmm_folder HMM_FOLDER\n",
        "                        Folder containing the HMM profiles for the proteins to\n",
        "                        include in the cluster.\n",
        "\n",
        "Target Genomes:\n",
        "  -S SFILE, --SubjectFile SFILE\n",
        "                        Subject genome in Genbank format.\n",
        "  -F SFOLDER, --SubjectFolder SFOLDER\n",
        "                        Folder containing the subject genomes in Genbank\n",
        "                        format.\n",
        "  -E GBEXT, --Genbank file extension GBEXT\n",
        "                        Genbank file extension. Default .gb\n",
        "\n",
        "Output Folder:\n",
        "  -o RES_FOLDER, --Results_folder RES_FOLDER\n",
        "                        Results folder name.\n",
        "  --overwrite           Overwrite previous results.\n",
        "\n",
        "Running mode:\n",
        "  --only_blastp         Runs using only blast for the identification of\n",
        "                        homolog proteins.\n",
        "\n",
        "Cluster definition arguments:\n",
        "  -n PROTS_BETWEEN, --n_prots_between PROTS_BETWEEN\n",
        "                        Maximum number of proteins allowed between two\n",
        "                        consecutive genes in the query cluster. Default = half\n",
        "                        of proteins in the cluster\n",
        "  -M MAX_ALIEN_PROTS, --max_alien_prots MAX_ALIEN_PROTS\n",
        "                        Maximum number of proteins in the target cluster that\n",
        "                        are not present in the query cluster. Default = not\n",
        "                        limited (Number of proteins in cluster * 3).\n",
        "  -m MIN_TARGET_PROTS, --min_target_prots MIN_TARGET_PROTS\n",
        "                        Minimum of query proteins required to be found in\n",
        "                        target cluster. Default=3.)\n",
        "  --min_cluster_coverage MIN_CLUSTER_COVERAGE\n",
        "                        Minimum of cluster coverage, proportion. Default=.5.\n",
        "                        The program will use as minimum half of the query\n",
        "                        proteins. If you are running only with HMMs, this\n",
        "                        value should be the fraction of the HMM required in a\n",
        "                        cluster.)\n",
        "  -g GAP, --gap_penalty GAP\n",
        "                        Gap penalty for cluster alignment. Default = 10\n",
        "  --mismatch_score MISMATCH\n",
        "                        Mismatch score for cluster alignment. Alignment of\n",
        "                        genes that are not orthologs are penalized. Default =\n",
        "                        20\n",
        "\n",
        "Blast and HMMSearch options:\n",
        "  --local_blast_db LOCAL_BLAST_DB\n",
        "                        A local blastp database generated with makeblastdb\n",
        "                        program... <Folder name>\n",
        "  --Generate_local_db   A local blastp database will be generated from the\n",
        "                        proteome of all the analyzed subject sequences...\n",
        "  --Blast_DB BLASTP_DATABASE\n",
        "                        Database for remote blastp, used to retrieve homologs\n",
        "                        for HMM generation. Default=nr Available: nr,\n",
        "                        refseq_select, refseq_protein, landmark, swissprot,\n",
        "                        pataa, pdb, env_nr, tsa_nr\n",
        "  --Blast_evalue EVALUE\n",
        "                        E-value cut-off for remote blastp, used to retrieve\n",
        "                        homologs for HMM generation.\n",
        "  --Blast_max_targets MAX_TARGET\n",
        "                        Max√≠mum number of targets for Blastp search.\n",
        "                        Default=250\n",
        "  --Blast_qcov QCOV     Query coverage percent for Blastp search. Default=45\n",
        "  --Blast_scov SCOV     Subject coverage percent for Blastp search. Default=45\n",
        "  --hmm_evalue HMM_EVALUE\n",
        "                        E-value cut-off for hmmsearch. Default = 0.00001\n",
        "  --hmm_cover HMM_COVER\n",
        "                        HMM coverage cut-off for hmmsearch. Default = 45\n",
        "\n",
        "```\n",
        "\n",
        "Running in the default mode can be very slow, depending on the NCBI blast server load (runs -remote blastp searches).\n",
        "Sequence coverages are set to 45% to improve cluster detection. Using 70% of query coverage some clusters were not found.\n",
        "Also the maximum number of alien proteins (-M MAX_ALIEN_PROTS) and the maximum number of proteins allowed between two consecutive genes in the query cluster (-n PROTS_BETWEEN) should be adjusted for better sensibility.\n",
        "To get more sensibility in the detection of distant clusters (with similar gene composition but different organization) the --only_blastp mode is not recommended. It should be used to gain speed only.\n",
        "\n",
        "## Examples\n",
        "### 1. Extract cluster from genbank file and search using remote blast to build HMM\n",
        "```\n",
        "./scan_cluster -Q <query genome gb> -R <Replicon ID as in the gb file> -s <int: start coordinate> -e <int: end coordinate> -F <Folder: folder with all the genomes to use as subject> -o <Folder: output folder>\n",
        "```\n",
        "### 2. Extract cluster from genbank file and search using local blast to build HMM\n",
        "```\n",
        "./scan_cluster -Q <query genome gb> -R <Replicon ID as in the gb file> -s <int: start coordinate> -e <int: end coordinate> -F <Folder: folder with all the genomes to use as subject> -o <Folder: output folder> --Generate_local_db\n",
        "```\n",
        "\n",
        "### 3. Search for clusters using HMMs provided by the user\n",
        "```\n",
        "./scan_cluster -f <HMM folder: folder with the HMM for genes in the cluster> -F <Folder: folder with all the genomes to use as subject> -o <Folder: output folder>\n",
        "```\n",
        "\n",
        "#### 4. Search using a genbank file only containing the cluster of interest and using the blast only mode\n",
        "```\n",
        "./scan_cluster -q <genbank cluster file>  -F <Folder: folder with all the genomes to use as subject> --only_blastp -o <Folder: output folder>\n",
        "```\n"
      ],
      "metadata": {
        "id": "FW5kYu2VKArj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Install scan_cluster"
      ],
      "metadata": {
        "id": "k3Xp4n5KKJGr"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "2bikAE9pJV-Q"
      },
      "outputs": [],
      "source": [
        "#@markdown ## Install the required python modules, blast and hmmer.\n",
        "\n",
        "print('Installing the requirements for Scan cluster...')\n",
        "import os,sys\n",
        "from sys import platform\n",
        "from shutil import which\n",
        "import subprocess\n",
        "if not os.path.exists('requirements.txt'):\n",
        "  !wget https://github.com/maurijlozano/scan_cluster/raw/refs/heads/main/requirements.txt\n",
        "  os.system('pip install -r requirements.txt')\n",
        "\n",
        "if not os.path.exists('scan_cluster.py'):\n",
        "  !wget https://github.com/maurijlozano/scan_cluster/raw/refs/heads/main/scan_cluster.py\n",
        "\n",
        "\n",
        "if not platform.startswith(\"linux\"):\n",
        "    print('This program only works in linux systems...\\n')\n",
        "\n",
        "def is_installed(program):\n",
        "    \"\"\"Check whether `program` is on PATH and marked as executable.\"\"\"\n",
        "    return (which(program) != None)\n",
        "\n",
        "!sudo apt-get update  >/dev/null 2>&1\n",
        "!sudo apt-get upgrade -y  >/dev/null 2>&1\n",
        "\n",
        "\n",
        "if not is_installed('blastp'):\n",
        "    os.system('sudo apt install ncbi-blast+')\n",
        "    print(f'Blast is installed: {which(\"blastp\")}')\n",
        "else:\n",
        "    print(f'Blast is installed: {which(\"blastp\")}')\n",
        "\n",
        "if not is_installed('hmmsearch'):\n",
        "    os.system('sudo apt install hmmer')\n",
        "    print(f'HMMER is installed: {which(\"hmmsearch\")}')\n",
        "else:\n",
        "    print(f'HMMER is installed: {which(\"hmmsearch\")}')\n",
        "\n",
        "if not is_installed('mafft'):\n",
        "    os.system('sudo apt install mafft')\n",
        "    print(f'mafft is installed: {which(\"mafft\")}')\n",
        "else:\n",
        "    print(f'mafft is installed: {which(\"mafft\")}')\n",
        "\n",
        "\n",
        "if not os.path.exists('./datasets'):\n",
        "  print('Instalando Datasets')\n",
        "  !wget https://ftp.ncbi.nlm.nih.gov/pub/datasets/command-line/v2/linux-amd64/datasets 2> /dev/null 1>> logs.txt\n",
        "  !chmod +x datasets\n",
        "else:\n",
        "  print('Datasets already installed...')\n",
        "\n",
        "\n",
        "if os.path.exists('scan_cluster.py'):\n",
        "    os.system('chmod +x scan_cluster.py')\n",
        "    print(f'\\n\\nTesting scan_cluster')\n",
        "    process = subprocess.run([f'./scan_cluster.py','-h'], capture_output=True, text=True)\n",
        "    print(process.stdout)\n",
        "else:\n",
        "    print('scan_cluster.py not found in current folder.')\n",
        "\n",
        "scan_cluster = './scan_cluster.py'\n",
        "datasets = './datasets'\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Download genomes from NCBI"
      ],
      "metadata": {
        "id": "y1hj18gvA7Hx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown # Query Cluster\n",
        "#@markdown Download refernce genome for cluster definition / Upload cluster in Genebank format\n",
        "from google.colab import files\n",
        "\n",
        "\n",
        "select_query_mode = 'NCBI accession' #@param ['NCBI accession', 'Upload']\n",
        "\n",
        "#@markdown <br>\n",
        "\n",
        "#@markdown **NCBI download mode**\n",
        "\n",
        "#@markdown Required: accession number of the genome containing the query cluster, replicon id, and start and end coordinates.\n",
        "reference_genome_accession = '' #@param {type: 'string'}\n",
        "acc = reference_genome_accession\n",
        "\n",
        "replicon = '' #@param {type:'string'}\n",
        "cluster_start = -1 #@param {type:'integer'}\n",
        "cluster_end = -1 #@param {type:'integer'}\n",
        "\n",
        "if not os.path.exists('/content/genomes'):\n",
        "  os.mkdir('/content/genomes')\n",
        "\n",
        "try:\n",
        "  if (select_query_mode == 'NCBI accession') and (len(acc) > 0):\n",
        "    if not os.path.exists(f'/content/genomes/{acc}.gb'):\n",
        "      print(f'Downloading {acc} genome...')\n",
        "      try:\n",
        "        !./datasets download genome accession {acc} --include gbff --filename {acc}.zip >/dev/null 2>&1\n",
        "        !unzip -o -j {acc}.zip ncbi_dataset/data/{acc}/genomic.gbff -d ./ >/dev/null 2>&1\n",
        "        os.remove(f'{acc}.zip')\n",
        "        !mv genomic.gbff /content/genomes/{acc}.gb >/dev/null 2>&1\n",
        "        refgenome = f'/content/genomes/{acc}.gb'\n",
        "        print(f'The reference genome ({acc}) was downloaded to {refgenome}...')\n",
        "      except:\n",
        "        print(f'Error: {acc} not found')\n",
        "    else:\n",
        "      refgenome = f'/content/genomes/{acc}.gb'\n",
        "      print(f'The reference genome ({acc}) was already downloaded...')\n",
        "  elif select_query_mode == 'Upload':\n",
        "    uploaded_files = files.upload()\n",
        "    print('Uploaded Cluster:', end = '')\n",
        "    refgenome = list(uploaded_files.keys())[0]\n",
        "    print(f'{refgenome} ', end = '')\n",
        "  else:\n",
        "    print('No genomes to download. Species name or Assembly accession list not provided.')\n",
        "except:\n",
        "  print('Error: Something went wrong')"
      ],
      "metadata": {
        "cellView": "form",
        "id": "vvX0DWR3C5Sn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown #Download Target genomes\n",
        "#@markdown **Input**: a _genus_ _species_ name, a comma separated list of NCBI assembly accession numbers or upload your genomes\n",
        "#get accessions or sp\n",
        "\n",
        "import shutil, re\n",
        "\n",
        "select_mode = 'Genus species' #@param ['NCBI accessions', 'Genus species', 'Upload']\n",
        "get_sp = False\n",
        "get_acc = False\n",
        "upload = False\n",
        "\n",
        "if select_mode == 'NCBI accessions':\n",
        "  get_acc = True\n",
        "elif select_mode == 'Genus species':\n",
        "  get_sp = True\n",
        "elif select_mode == 'Upload':\n",
        "  upload = True\n",
        "\n",
        "#@markdown <br>\n",
        "\n",
        "#@markdown ##Get genomes by genus and species.\n",
        "#@markdown Input a comma separated list of the _genus species_ to download\n",
        "\n",
        "get_species_genomes = '' #@param {type: 'string'}\n",
        "get_species_genomes = re.sub(', ',',',get_species_genomes)\n",
        "\n",
        "get_species_genomes = get_species_genomes.split(',')\n",
        "\n",
        "#assembly level filter\n",
        "assembly_level = True #@param {type: 'boolean'}\n",
        "if assembly_level:\n",
        "  assembly_level_flag = '--assembly-level complete'\n",
        "else:\n",
        "  assembly_level_flag = \"\"\n",
        "\n",
        "#Annotated\n",
        "annotated = True #@param {type: 'boolean'}\n",
        "if annotated:\n",
        "  annotated_flag = '--annotated'\n",
        "else:\n",
        "  annotated_flag = \"\"\n",
        "\n",
        "#exclude-atypical\n",
        "exclude_atypical = True #@param {type: 'boolean'}\n",
        "if exclude_atypical:\n",
        "  exclude_atypical_flag = '--exclude-atypical'\n",
        "else:\n",
        "  exclude_atypical_flag = \"\"\n",
        "\n",
        "#refseq only\n",
        "refseq_only = True #@param {type: 'boolean'}\n",
        "if refseq_only:\n",
        "  refseq_only_flag = '--assembly-source RefSeq'\n",
        "else:\n",
        "  refseq_only_flag = \"\"\n",
        "\n",
        "#@markdown <br>\n",
        "\n",
        "#@markdown ### Use if you want to download from NCBI a list of accession numbers.\n",
        "#@markdown Input: list of comma separated accession numbers separated by spaces.\n",
        "genome_accessions = '' #@param {type: 'string'}\n",
        "genome_accessions = re.sub(' ','',genome_accessions)\n",
        "genome_accessions_list = genome_accessions.split(',')\n",
        "\n",
        "\n",
        "\n",
        "import os, glob\n",
        "\n",
        "if not os.path.exists('/content/genomes'):\n",
        "  os.mkdir('/content/genomes')\n",
        "else:\n",
        "  files_in_folder = glob.glob('/content/genomes/*.gb')\n",
        "  print(f'Genomes folder already exists. Genomes already downloaded:')\n",
        "  for f in files_in_folder:\n",
        "    print(f'{f}')\n",
        "  print(f'Scan_cluster uses all the genomes in /content/genomes/ as target genomes. Pleas delete all the unwanted genomes.')\n",
        "\n",
        "\n",
        "genome_files = []\n",
        "\n",
        "try:\n",
        "  if get_sp and (len(get_species_genomes) > 0):\n",
        "    for sp in get_species_genomes:\n",
        "      print(f'Downloading {sp} genomes...')\n",
        "      try:\n",
        "        !./datasets download genome taxon \"{sp}\" --include gbff {assembly_level_flag} {exclude_atypical_flag } {refseq_only_flag} >/dev/null 2>&1\n",
        "        !unzip -o ncbi_dataset >/dev/null 2>&1\n",
        "        genome_list = glob.glob('/content/ncbi_dataset/data/*/**/*.gbff', recursive=True)\n",
        "        base_names = {os.path.split(os.path.split(i)[0])[1]:i for i in genome_list}\n",
        "        for i in base_names.keys():\n",
        "          gfile = f'/content/genomes/{i}.gb'\n",
        "          !mv {base_names[i]} {gfile}\n",
        "          genome_files.append(gfile)\n",
        "        os.remove(f'/content/ncbi_dataset.zip')\n",
        "        shutil.rmtree('/content/ncbi_dataset')\n",
        "      except:\n",
        "        print(f'--> Error: {sp} not found. Please verify the organism name.')\n",
        "  elif get_acc and len(genome_accessions_list) > 0 :\n",
        "    for acc in genome_accessions_list:\n",
        "      if not os.path.exists(f'/content/genomes/{acc}.gb'):\n",
        "        print(f'Downloading {acc} genome...')\n",
        "        try:\n",
        "          !./datasets download genome accession {acc} --include gbff --filename {acc}.zip >/dev/null 2>&1\n",
        "          !unzip -o -j {acc}.zip ncbi_dataset/data/{acc}/genomic.gbff -d ./ >/dev/null 2>&1\n",
        "          os.remove(f'{acc}.zip')\n",
        "          !mv genomic.gbff /content/genomes/{acc}.gb >/dev/null 2>&1\n",
        "          genome_files.append(f'/content/genomes/{acc}.gb')\n",
        "        except:\n",
        "          print(f'Error: {acc} not found')\n",
        "      else:\n",
        "        genome_files.append(f'/content/genomes/{acc}.gb')\n",
        "        print(f'The reference genome ({acc}) was already downloaded...')\n",
        "  elif upload:\n",
        "    uploaded_files = files.upload()\n",
        "    print('Uploaded genomes:', end = '')\n",
        "    genome_files = list(uploaded_files.keys())\n",
        "    for gn in genome_files:\n",
        "      print(f'{gn} ', end = '')\n",
        "  else:\n",
        "    print('No genomes to download. Genus species name, assembly accession list or upload your files.')\n",
        "except:\n",
        "  print('Error: Something went wrong')\n",
        "\n",
        "print('Done!')\n",
        "genome_files = list(set(genome_files))"
      ],
      "metadata": {
        "id": "VaUMsIwF42xx",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown ###Use this block if you want to zip and download all the genomes to a local computer\n",
        "import os\n",
        "import shutil\n",
        "from google.colab import files\n",
        "zip_downoad = False #@param {type:'boolean'}\n",
        "\n",
        "if zip_downoad:\n",
        "  if not os.path.exists('/content/genomes.zip'):\n",
        "    !zip -r /content/genomes.zip /content/genomes\n",
        "  files.download(\"/content/genomes.zip\")"
      ],
      "metadata": {
        "cellView": "form",
        "id": "XAVDuGjMf3P6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown ##Generate a table with information of the downloaded genomes\n",
        "from Bio import SeqIO\n",
        "import re, glob\n",
        "\n",
        "target_genome_files = glob.glob('/content/genomes/*.gb')\n",
        "with open('genomes.csv','w') as tf:\n",
        "  tf.write('Assembly Accession number,Organism,Taxonomy,Description,Comments\\n')\n",
        "  for gnome in target_genome_files:\n",
        "    acc = os.path.splitext(os.path.basename(gnome))[0]\n",
        "    r = list(SeqIO.parse(gnome,'gb'))[0]\n",
        "    if len(r.annotations['organism']) > 0:\n",
        "      org = r.annotations['organism']\n",
        "    else:\n",
        "      org = ''\n",
        "    if len(r.annotations['taxonomy']) > 0:\n",
        "      tax = '; '.join(r.annotations['taxonomy'])\n",
        "    else:\n",
        "      tax = ''\n",
        "    desc = re.sub(',',';',r.description)\n",
        "    desc = re.sub(' ?[Cc][Oo][Nn][Tt][Ii][Gg].*','',desc)\n",
        "    desc = re.sub(' ?[Nn][Oo][Dd][Ee].*','',desc)\n",
        "    desc = re.sub(' ?[Ss][cC][aA][Ff].*','',desc)\n",
        "    desc = re.sub(' ?[Pp][Ll][aA][Ss].*','',desc)\n",
        "    desc = re.sub(' ?[Cc][Hh][Rr][Oo].*','',desc)\n",
        "    if 'comment' in r.annotations.keys():\n",
        "      if len(r.annotations['comment']) > 0:\n",
        "        comments = re.sub('[,]','; ',r.annotations['comment'])\n",
        "        comments = re.sub('\\n',' ',comments)\n",
        "    else:\n",
        "      comments = ''\n",
        "    tf.write(f'{acc},{org},{tax},{desc},{comments}\\n')\n",
        "\n",
        "from google.colab import files\n",
        "download_table = False #@param {type:'boolean'}\n",
        "\n",
        "if download_table:\n",
        "  files.download('genomes.csv')\n",
        "\n",
        "import pandas as pd\n",
        "table = pd.read_csv('genomes.csv')\n",
        "table"
      ],
      "metadata": {
        "cellView": "form",
        "id": "xp5GACITmOtW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Run scan_cluster"
      ],
      "metadata": {
        "id": "6H5LzlN8Cj6Q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown Run with the default options in local mode and defining a cluster by its genomic coordinates in the reference genome.\n",
        "select_running_mode = 'default' #@param ['default','hmm','command_line']\n",
        "hmm_folder =  '' #@param {type:'string'}\n",
        "overwrite = True #@param {type:'boolean'}\n",
        "if overwrite:\n",
        "  overwrite_flag = '--overwrite'\n",
        "else:\n",
        "  overwrite_flag = ''\n",
        "#@markdown <br>\n",
        "\n",
        "\n",
        "#@markdown ###Additional Options: for default values use -1\n",
        "#@markdown Maximum number of proteins allowed between two consecutive genes in the query cluster. Default = half of proteins in the cluster\"\n",
        "n_prots_between = -1 #@param {type:'integer'}\n",
        "if n_prots_between > 0:\n",
        "  n_prots_between_flag = f'-n {n_prots_between}'\n",
        "else:\n",
        "  n_prots_between_flag = ''\n",
        "\n",
        "#@markdown Maximum number of proteins in the target cluster that are not present in the query cluster. Default = not limited\n",
        "max_alien_prots = -1 #@param {type:'integer'}\n",
        "if max_alien_prots > 0:\n",
        "  max_alien_prots_flag = f'-M {max_alien_prots}'\n",
        "else:\n",
        "  max_alien_prots_flag = ''\n",
        "\n",
        "#@markdown Minimum of query proteins required to be found in target cluster.\n",
        "min_target_prots = -1 #@param {type:'integer'}\n",
        "if min_target_prots > 0:\n",
        "  min_target_prots_flag = f'-m {min_target_prots}'\n",
        "else:\n",
        "  min_target_prots_flag = ''\n",
        "\n",
        "#@markdown Minimum of cluster coverage, proportion. Default=.5. The program will use as minimum half of the query proteins. If you are running only with HMMs, this value should be the fraction of the HMM required in a cluster.\n",
        "min_cluster_coverage = -1 #@param {type:'number'}\n",
        "if min_cluster_coverage > 0:\n",
        "  min_cluster_coverage_flag = f'--min_cluster_coverage {min_cluster_coverage}'\n",
        "else:\n",
        "  min_cluster_coverage_flag = ''\n",
        "\n",
        "#@markdown Homologous search coverage [ For both blastp and hmmsearch ]\n",
        "min_coverage = 45 #@param {type:'integer'}\n",
        "if min_coverage > 0:\n",
        "  min_coverage_flag = f'--Blast_qcov {min_coverage} --Blast_scov {min_coverage} --hmm_cover {min_coverage}'\n",
        "else:\n",
        "  min_coverage_flag = ''\n",
        "\n",
        "#@markdown <br>\n",
        "cluster_found = False\n",
        "\n",
        "if select_running_mode == 'default':\n",
        "  print(f'Running with default options. \\nRef genome: {refgenome}\\nReplicon: {replicon}\\nCluster start: {cluster_start}\\nCluster end: {cluster_end}')\n",
        "  if not select_query_mode == 'Upload' :\n",
        "    if os.path.exists(refgenome):\n",
        "      for r in SeqIO.parse(refgenome,'gb'):\n",
        "        if r.id == replicon:\n",
        "          if (cluster_start > 0) and (cluster_end > 0):\n",
        "            cluster = r[cluster_start:cluster_end]\n",
        "            for f in cluster.features:\n",
        "              if (f.type == 'CDS') and ('locus_tag' in f.qualifiers) and ('product' in f.qualifiers):\n",
        "                print(f\"{f.qualifiers['locus_tag'][0]} - {f.qualifiers['product'][0]}\")\n",
        "            cluster_found = True\n",
        "            break\n",
        "  else:\n",
        "    cluster_found = True\n",
        "  if cluster_found:\n",
        "    if select_query_mode == 'Upload' :\n",
        "      !./scan_cluster.py -q {refgenome} -F /content/genomes/ --Generate_local_db {overwrite_flag} {n_prots_between_flag} {max_alien_prots_flag} {min_target_prots_flag} {min_cluster_coverage_flag} {min_coverage_flag}\n",
        "    else:\n",
        "      !./scan_cluster.py -Q {refgenome} -R {replicon} -s {cluster_start} -e {cluster_end} -F /content/genomes/ --Generate_local_db {overwrite_flag} {n_prots_between_flag} {max_alien_prots_flag} {min_target_prots_flag} {min_cluster_coverage_flag} {min_coverage_flag}\n",
        "  else:\n",
        "    print('Cluster not found')\n",
        "elif select_running_mode == 'command_line':\n",
        "  print(f'Running with command line mode.')\n",
        "  #@markdown ###For customized options run the command line mode:\n",
        "  cl = '' #@param {type:'string'}\n",
        "  !{cl}\n",
        "elif select_running_mode == 'hmm':\n",
        "  print(f'Running with hmm mode.')\n",
        "  if len(hmm_folder) > 0:\n",
        "    if os.path.exists(f'{hmm_folder}'):\n",
        "      hmms = glob.glob(f'{hmm_folder}/*.hmm')\n",
        "      if len(hmms) > 0:\n",
        "        print(f'Found {len(hmms)} files in {hmm_folder}')\n",
        "        !./scan_cluster.py -f {hmm_folder} -F /content/genomes/ {overwrite_flag} {n_prots_between_flag} {max_alien_prots_flag} {min_target_prots_flag} {min_cluster_coverage_flag} {min_coverage_flag}\n",
        "      else:\n",
        "        print(f'No hmm files found in {hmm_folder}')\n",
        "    else:\n",
        "      print(f'No hmm folder: {hmm_folder}. ')\n",
        "  else:\n",
        "    print('A folder with the HMM files is required...')\n",
        "\n"
      ],
      "metadata": {
        "id": "fRmpahzR0xRU",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown ## Ascii draw tree\n",
        "from Bio import Phylo\n",
        "import os\n",
        "import re\n",
        "\n",
        "tree_file = '/content/Results/tree.nhx' #@param {type:'string'}\n",
        "if os.path.exists(tree_file):\n",
        "  tree = Phylo.read(tree_file,'nexus')\n",
        "  if os.path.exists('genomes.csv'):\n",
        "    table = pd.read_csv('genomes.csv')\n",
        "    rename = {row['Assembly Accession number']:row['Description'].split(';')[0] for _,row in table.iterrows() }\n",
        "    for leaf in tree.get_terminals():\n",
        "      name = leaf.name.split('__')[0]\n",
        "      rep = leaf.name.split('__')[1]\n",
        "      coords = leaf.name.split('__')[2]\n",
        "      if name in rename.keys():\n",
        "        leaf.name = re.sub(':','',f'{rename[name]}__{rep}__{coords}')\n",
        "  Phylo.draw_ascii(tree)\n",
        "  Phylo.write(tree,'tree.nwk','newick')\n",
        "else:\n",
        "  print(f'{tree_file} not found')\n",
        "\n",
        "import re\n",
        "with open('tree.nwk','r') as infile, open('tmp.txt','w') as outfile:\n",
        "  for line in infile:\n",
        "    line = re.sub(\"\\\\'\",\"\",line)\n",
        "    outfile.write(line)\n",
        "!mv tmp.txt tree.nwk\n",
        "\n",
        "\n",
        "iTolAnnotation = '/content/Results/iTOLData.txt' #@param {type:'string'}\n",
        "if os.path.exists(iTolAnnotation):\n",
        "  with open(iTolAnnotation,'r') as r, open('iTolData_rn.txt','w') as w:\n",
        "    for line in r:\n",
        "      if 'GCF' in line:\n",
        "        a=line.split(',')[0].split('__')\n",
        "        a = f'{rename[a[0]]}__{a[1]}__{a[2]}'\n",
        "        a = re.sub(':','',a)\n",
        "        b=','.join(line.split(',')[1:])\n",
        "        w.write(f'{a},{b}')\n",
        "      else:\n",
        "        w.write(line)\n",
        "\n"
      ],
      "metadata": {
        "id": "m-7ap-YjQboo",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}